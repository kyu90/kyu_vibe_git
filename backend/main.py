from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, Any
import os
from dotenv import load_dotenv

from chart_generator import ChartGenerator

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = FastAPI(title="ê°„ë‹¨í•œ ì°¨íŠ¸ë´‡")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì°¨íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™” (llama3 ëª¨ë¸ ì‚¬ìš©)
chart_generator = ChartGenerator(model_name="llama3:latest")

class ChatMessage(BaseModel):
    message: str

class ChatResponse(BaseModel):
    response: str
    chart_data: Optional[Dict[str, Any]] = None

@app.get("/")
def read_root():
    ollama_status = chart_generator.test_connection()
    return {
        "message": "ê°„ë‹¨í•œ ì°¨íŠ¸ë´‡ API ì‹¤í–‰ì¤‘! ğŸ¤–ğŸ“Š",
        "ollama_connected": ollama_status,
        "model": "llama3:latest"
    }

@app.post("/chat")
def chat_endpoint(chat_message: ChatMessage):
    """ê°„ë‹¨í•œ ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸"""
    
    try:
        # Ollama ì—°ê²° í™•ì¸
        if not chart_generator.test_connection():
            return ChatResponse(
                response="Ollamaê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'ollama serve' ëª…ë ¹ì–´ë¡œ ì‹œì‘í•´ì£¼ì„¸ìš”."
            )
        
        # AI ë¶„ì„
        response_text, chart_config, chart_meta = chart_generator.analyze_user_request(chat_message.message)
        
        chart_data = None
        
        # ì°¨íŠ¸ ìƒì„±ì´ í•„ìš”í•œ ê²½ìš°
        if chart_config and chart_meta:
            extracted_data = chart_generator.parse_data_from_text(chat_message.message)
            if extracted_data:
                chart_data = chart_generator.generate_chart_config(
                    chart_meta["type"], 
                    extracted_data, 
                    chart_config
                )
        
        return ChatResponse(
            response=response_text,
            chart_data=chart_data
        )
        
    except Exception as e:
        return ChatResponse(
            response=f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

if __name__ == "__main__":
    import uvicorn
    
    print("ğŸš€ ê°„ë‹¨í•œ ì°¨íŠ¸ë´‡ ì„œë²„ ì‹œì‘!")
    print("ğŸ¦™ Ollama ì—°ê²° ìƒíƒœ:", chart_generator.test_connection())
    print("ğŸ“¡ ì‚¬ìš© ëª¨ë¸: llama3:latest")
    print("ğŸŒ ì„œë²„ ì£¼ì†Œ: http://localhost:8000")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)
